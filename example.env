# Generic
MODEL_N_CTX=1024
TEXT_EMBEDDINGS_MODEL=all-MiniLM-L6-v2  # For HF, can be HF name
TEXT_EMBEDDINGS_MODEL_TYPE=HF  # LlamaCpp or HF
USE_MLOCK=true

# Ingestion
PERSIST_DIRECTORY=db
DOCUMENTS_DIRECTORY=source_documents
INGEST_CHUNK_SIZE=500
INGEST_CHUNK_OVERLAP=50

# Generation
MODEL_TYPE=LlamaCpp # GPT4All or LlamaCpp or Ctransformers
CTRANSFORMERS_MODEL_TYPE=gptj # Only with Ctransformers: gpt2, gptj, gpt_neox, dolly-v2, starcoder
MODEL_PATH=models/ggml-vic7b-q5_1.bin  # For Ctransformers, can be HF name
MODEL_TEMP=0.8
MODEL_STOP=[STOP]
CHAIN_TYPE=stuff
N_GPU_LAYERS=4
